{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval Augmented FuctionCallingAgent\n",
    "\n",
    "\n",
    "In this tutorial, we demonstrate how to utilize our `FunctionCallingAgent `implementation alongside a tool retriever.\n",
    "\n",
    "The goal is to construct an agent that leverages the function-calling API of LLMs (such as OpenAI, Anthropic, or Mistral) to manage and index an arbitrary number of tools.\n",
    "\n",
    "Our indexing and retrieval modules are designed to simplify the process, addressing the challenge of accommodating numerous functions within a prompt.\n",
    "\n",
    "`FunctionCallingAgent` uses LLM function calling capabilities to complete the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/omprakash/lama-index/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/omprakash/lama-index/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.llms.openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.core.tools import BaseTool, FunctionTool\n",
    "from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "from llama_index.core.agent import AgentRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two integers and returns the result integer\"\"\"\n",
    "    return a * b\n",
    "\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two integers with and returns the result integer\"\"\"\n",
    "    return a + b\n",
    "\n",
    "def subtract(a: int, b: int) -> int:\n",
    "    \"\"\"Subtract two integers with and returns the result integer\"\"\"\n",
    "    return a - b\n",
    "\n",
    "def useless(a: int, b: int) -> int:\n",
    "    \"\"\"Toy useless function.\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiply_tool = FunctionTool.from_defaults(fn=multiply)\n",
    "add_tool = FunctionTool.from_defaults(fn=add)\n",
    "subtract_tool = FunctionTool.from_defaults(fn=subtract)\n",
    "\n",
    "useless_tools = [\n",
    "    FunctionTool.from_defaults(fn=useless, name=f\"useless_{str(idx)}\")\n",
    "    for idx in range(50)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tools = [multiply_tool] + [add_tool] + [subtract_tool] + useless_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an \"object\" index over these tools\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.objects import ObjectIndex\n",
    "\n",
    "obj_index = ObjectIndex.from_objects(\n",
    "    all_tools,\n",
    "    index_cls=VectorStoreIndex,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    tool_retriever=obj_index.as_retriever(similarity_top_k=2),\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    allow_parallel_tool_calls=False,\n",
    ")\n",
    "agent = AgentRunner(agent_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: What's 500 multiplied by 10?\n",
      "=== Calling Function ===\n",
      "Calling function: multiply with args: {\"a\": 500, \"b\": 10}\n",
      "=== Function Output ===\n",
      "5000\n",
      "=== LLM Response ===\n",
      "500 multiplied by 10 is 5000.\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"What's 500 multiplied by 10?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: 500 multiplied by 10 is 5000.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: What's 500 multiplied by 10 and then subtract 1000?\n",
      "=== Calling Function ===\n",
      "Calling function: multiply with args: {\"a\": 500, \"b\": 10}\n",
      "=== Function Output ===\n",
      "5000\n",
      "=== Calling Function ===\n",
      "Calling function: subtract with args: {\"a\": 5000, \"b\": 1000}\n",
      "=== Function Output ===\n",
      "4000\n",
      "=== LLM Response ===\n",
      "500 multiplied by 10 and then subtracting 1000 results in 4000.\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"What's 500 multiplied by 10 and then subtract 1000?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG QueryEngine Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import (\n",
    "    SimpleDirectoryReader,\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    storage_context = StorageContext.from_defaults(\n",
    "        persist_dir=\"./storage/lyft\"\n",
    "    )\n",
    "    lyft_index = load_index_from_storage(storage_context)\n",
    "\n",
    "    storage_context = StorageContext.from_defaults(\n",
    "        persist_dir=\"./storage/uber\"\n",
    "    )\n",
    "    uber_index = load_index_from_storage(storage_context)\n",
    "\n",
    "    index_loaded = True\n",
    "except:\n",
    "    index_loaded = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not index_loaded:\n",
    "    # load data\n",
    "    lyft_docs = SimpleDirectoryReader(\n",
    "        input_files=[\"./data/10k/lyft_2021.pdf\"]\n",
    "    ).load_data()\n",
    "    uber_docs = SimpleDirectoryReader(\n",
    "        input_files=[\"./data/10k/uber_2021.pdf\"]\n",
    "    ).load_data()\n",
    "\n",
    "    # build index\n",
    "    lyft_index = VectorStoreIndex.from_documents(lyft_docs)\n",
    "    uber_index = VectorStoreIndex.from_documents(uber_docs)\n",
    "\n",
    "    # persist index\n",
    "    lyft_index.storage_context.persist(persist_dir=\"./storage/lyft\")\n",
    "    uber_index.storage_context.persist(persist_dir=\"./storage/uber\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyft_engine = lyft_index.as_query_engine(similarity_top_k=3)\n",
    "uber_engine = uber_index.as_query_engine(similarity_top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine_tools = [\n",
    "    QueryEngineTool(\n",
    "        query_engine=lyft_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"lyft_10k\",\n",
    "            description=(\n",
    "                \"Provides information about Lyft financials for year 2021. \"\n",
    "                \"Use a detailed plain text question as input to the tool.\"\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "    QueryEngineTool(\n",
    "        query_engine=uber_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"uber_10k\",\n",
    "            description=(\n",
    "                \"Provides information about Uber financials for year 2021. \"\n",
    "                \"Use a detailed plain text question as input to the tool.\"\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_index = ObjectIndex.from_objects(\n",
    "    query_engine_tools,\n",
    "    index_cls=VectorStoreIndex,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    tool_retriever=obj_index.as_retriever(similarity_top_k=1),\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    allow_parallel_tool_calls=True,\n",
    ")\n",
    "agent = AgentRunner(agent_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: What is the revenue of Uber in 2021?\n",
      "=== Calling Function ===\n",
      "Calling function: uber_10k with args: {\"input\": \"What is the revenue of Uber in 2021?\"}\n",
      "=== Function Output ===\n",
      "Encountered error: shapes (1536,) and (384,) not aligned: 1536 (dim 0) != 384 (dim 0)\n",
      "=== LLM Response ===\n",
      "It seems there was an error in retrieving the revenue information for Uber in 2021. Let me try to fetch the information again.\n",
      "=== Calling Function ===\n",
      "Calling function: uber_10k with args: {\"input\": \"revenue of Uber in 2021\"}\n",
      "=== Function Output ===\n",
      "Encountered error: shapes (1536,) and (384,) not aligned: 1536 (dim 0) != 384 (dim 0)\n",
      "=== LLM Response ===\n",
      "I apologize for the inconvenience. It seems there is still an issue with retrieving the revenue information for Uber in 2021. Let me attempt to gather the information using a different approach.\n",
      "=== Calling Function ===\n",
      "Calling function: uber_10k with args: {\"input\": \"revenue of Uber in 2021\"}\n",
      "=== Function Output ===\n",
      "Encountered error: shapes (1536,) and (384,) not aligned: 1536 (dim 0) != 384 (dim 0)\n",
      "=== Calling Function ===\n",
      "Calling function: uber_10k with args: {\"input\": \"financial performance of Uber in 2021\"}\n",
      "=== Function Output ===\n",
      "Encountered error: shapes (1536,) and (384,) not aligned: 1536 (dim 0) != 384 (dim 0)\n",
      "=== LLM Response ===\n",
      "It seems there are still issues with retrieving the revenue information for Uber in 2021. Unfortunately, I am unable to provide the specific revenue figure at this time. If you have any other questions or need assistance with a different topic, feel free to let me know.\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\n",
    "    \"What is the revenue of Uber in 2021?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
